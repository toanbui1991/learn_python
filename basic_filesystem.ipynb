{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import json\n",
    "\n",
    "directory = './filesystem_test/'\n",
    "if not os.path.isdir(directory):\n",
    "    os.mkdir(directory)\n",
    "\n",
    "for i in range(3):\n",
    "    content = 'a' * i\n",
    "    with open('{}/{}.txt'.format(directory, i), 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# move to filesystem_test\n",
    "# os.chdir(directory) #do not use method chdir, just reference directory path with \n",
    "#create 3 folder\n",
    "for i in range(3):\n",
    "    sub_directory = '{}/{}'.format(directory, str(i))\n",
    "    if not os.path.isdir(sub_directory):\n",
    "        os.mkdir(sub_directory)\n",
    "    for y in range(100):\n",
    "        if y % 2 == 0:\n",
    "            content = str(y) * 10\n",
    "            with open('{}/{}/{}.txt'.format(directory, i, y), 'w') as file:\n",
    "                file.write(content)\n",
    "        else: \n",
    "            content = {y: str(y)}\n",
    "            content = json.dumps(content)\n",
    "            with open('{}/{}/{}.json'.format(directory, i, y), 'w') as file:\n",
    "                file.write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./filesystem_test\\\\0', './filesystem_test\\\\0.txt', './filesystem_test\\\\1', './filesystem_test\\\\1.txt', './filesystem_test\\\\2', './filesystem_test\\\\2.txt']\n",
      "file_data size: 150\n",
      "file_data size: 300\n",
      "len of file_paths: 150\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "#glob.glob() will return a list of all paths in a given directory level with syntax **\n",
    "#note: glob is work with file pattern not with file system tree\n",
    "file_pattern = './filesystem_test/**'\n",
    "file_paths = glob.glob(file_pattern)\n",
    "print(file_paths)\n",
    "#list all text file\n",
    "file_pattern = \"./filesystem_test/**/*.txt\"\n",
    "file_paths = glob.glob(file_pattern)\n",
    "file_data = pd.DataFrame({\"file_paths\": file_paths})\n",
    "print('file_data size: {}'.format(file_data.size))\n",
    "#list all files\n",
    "file_pattern = \"./filesystem_test/**/*\"\n",
    "file_paths = glob.glob(file_pattern)\n",
    "file_data = pd.DataFrame({\"file_paths\": file_paths})\n",
    "print('file_data size: {}'.format(file_data.size))\n",
    "#list all json file:\n",
    "file_pattern = './filesystem_test/**/*.json'\n",
    "file_paths = glob.glob(file_pattern)\n",
    "print('len of file_paths: {}'.format(len(file_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of path_paths: 303\n",
      "len of file_paths after filter:  153\n"
     ]
    }
   ],
   "source": [
    "#learn how to use os.walk()\n",
    "import os\n",
    "import re\n",
    "directory = './filesystem_test'\n",
    "count = 0\n",
    "#os.walk() will loop through the files system from the current top directory\n",
    "#os.walk() return root: current root directory, dirs a list of directory under root, files are files under root directory\n",
    "#collection or all under a directory\n",
    "#str do not have contains method to check substring in larger string use substring in string test\n",
    "file_paths = []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = '{}/{}'.format(root, file)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "print('len of path_paths: {}'.format(len(file_paths)))\n",
    "# #filter with str nembership test with in\n",
    "# file_paths = [file_path for file_path in file_paths if '.txt' in file_path]\n",
    "# fileter with re.search() to maker .txt is at the end of the file name\n",
    "# try to reduce error each time we run the code, always check argument and then function before run the code\n",
    "# $ mean  you position is at the en of line.\n",
    "# \\ mean except special character. \\. mean match dot litterally while dot means match anything except new line\n",
    "# therfore \\.txt$  means check the end of string which have .txt\n",
    "# ^ mean assert position as start \n",
    "file_paths = [file_path for file_path in file_paths if re.search(r'\\.txt$', file_path)]\n",
    "print('len of file_paths after filter: ', len(file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary on os.walk() vs glob.glob():**\n",
    "- glob.glob() will return a file list given the pattern but do not parse all directory tree\n",
    "- os.walk() loop through direcotry tree with return root (current root directory), dirs (directories under the current root), files (files under the current root)\n",
    "- os.wall() does loop through all paths in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary on filesystem:**\n",
    "- to work with file system we can use package like os, glob.\n",
    "- os methods: os.mkdir(), os.path.isdir(), os.path.isfile(), os.path.join()\n",
    "- glob methods: glob.glob().\n",
    "- glob.glob(file_pattern) will return a list of all paths given the file_pattern.\n",
    "- os.path have some methods: os.path.isdir(), os.path.isfile(), os.path.join(*path)\n",
    "- json package have methods: json.loads(), json.load(), json.dump(), json.dumps()\n",
    "- json.loads() convert json string into python dictionary object\n",
    "- json.load() work with open file system to write data from file into python dictionary object\n",
    "- json.dumps() covnert python dict object into json string\n",
    "- json.dump() wort with open file to write python dict into json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of json_string: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "test_dict = {\"1\": 1, \"2\": 2}\n",
    "json_string = json.dumps(test_dict) #json.dumps return str\n",
    "print('type of json_string: {}'.format(type(json_string)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e997c254a1f8079c5997e54e250cb3627d598fa1a1d92bf10438cfce758154e6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
