{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand Cache in spark:**\n",
    "- referenct to undrestand cache in spark: https://luminousmen.com/post/explaining-the-mechanics-of-spark-caching/\n",
    "- cache is the process of materialize rdd in ram or disk,\n",
    "- two method to perform cache: cache(), persist(persist_level)\n",
    "- cache: will store rdd in ram if possible, if not store in disk\n",
    "- persist: store rdd base on specify persist level\n",
    "- cache is not action and is not materilize until an action is call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of using cache() and unpersist().\n",
    "df = spark.read.parquet(data_path)\n",
    "df.cache() # Cache the data\n",
    "df.count() # Materialize the cache, command took 5.11 seconds\n",
    "df.is_cached # Determining whether a dataframe is cached\n",
    "df.count() # Now get it from the cache, command took 0.44 seconds\n",
    "df.storageLevel # Determing the persistent type (memory, deserialized, # replicas)\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of using cache with tempview and spark sql api\n",
    "df.createOrReplaceTempView('df')\n",
    "spark.catalog.cacheTable('df')\n",
    "spark.catalog.isCached(tableName='df')\n",
    "spark.catalog.uncacheTable('df')\n",
    "spark.catalog.clearCache() # Clear all the tables from cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand cache sequence in spark:**\n",
    "- spark command will go through logical planning and physical planning\n",
    "- logical planning: analyzer -> cache manager -> optimizer. cache manager will decide cache after analyzer. Therefore, cache will not use if we have different analyzer plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of cache is not use because we have different analyzer plan\n",
    "#it is best pratice to cache dataframe which we want to do many action on it.\n",
    "df = spark.read.parquet(data_path)\n",
    "df.select(col1, col2).filter(col2 > 0).cache()\n",
    "df.filter(col2 > 0).select(col1, col2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0acef43dc5f76a2ed31147fd429dfe8c79ee15b3b02be3263c02dc60771e7f23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
