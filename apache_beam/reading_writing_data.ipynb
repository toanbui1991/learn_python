{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading and Writing data with apache beam:**\n",
    "- reference link: https://colab.research.google.com/github/apache/beam/blob/master/examples/notebooks/tour-of-beam/reading-and-writing-data.ipynb#scrollTo=xDXdE9uysriw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "#using beam.io.ReadFromText(file_pattern)\n",
    "#ReadFromText to parse file for each line\n",
    "input_files = 'data/*.txt'\n",
    "with beam.Pipeline() as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | 'Read files' >> beam.io.ReadFromText(input_files)\n",
    "      | 'Print contents' >> beam.Map(print)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "#using beam.io.WriteToText() to write each line to a file\n",
    "output_file_name_prefix = 'outputs/file'\n",
    "with beam.Pipeline() as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | 'Create file lines' >> beam.Create([\n",
    "          'Each element must be a string.',\n",
    "          'It writes one element per line.',\n",
    "          'There are no guarantees on the line order.',\n",
    "          'The data might be written into multiple files.',\n",
    "      ])\n",
    "      | 'Write to files' >> beam.io.WriteToText(\n",
    "          output_file_name_prefix,\n",
    "          file_name_suffix='.txt')\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toanbui1991/python/learn_python/venv/lib/python3.10/site-packages/apache_beam/__init__.py:79: UserWarning: This version of Apache Beam has not been sufficiently tested on Python 3.10. You may encounter bugs or missing features.\n",
      "  warnings.warn(\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from typing import Iterable\n",
    "\n",
    "def count(n: int) -> Iterable[int]:\n",
    "  for i in range(n):\n",
    "    yield i\n",
    "\n",
    "n = 5\n",
    "with beam.Pipeline() as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | 'Create inputs' >> beam.Create([n])\n",
    "      | 'Generate elements' >> beam.FlatMap(count)\n",
    "      | 'Print elements' >> beam.Map(print)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from typing import Iterable\n",
    "\n",
    "#define your custom PTranform with decorator\n",
    "@beam.ptransform_fn\n",
    "@beam.typehints.with_input_types(beam.pvalue.PBegin)\n",
    "@beam.typehints.with_output_types(int)\n",
    "def Count(pbegin: beam.pvalue.PBegin, n: int) -> beam.PCollection[int]:\n",
    "  def count(n: int) -> Iterable[int]:\n",
    "    for i in range(n):\n",
    "      yield i\n",
    "  #this will use create Pcollection and then apply FlatMap to return a list \n",
    "  return (\n",
    "      pbegin\n",
    "      | 'Create inputs' >> beam.Create([n])\n",
    "      | 'Generate elements' >> beam.FlatMap(count) #FlatMap take input as element return iterable of elements\n",
    "  )\n",
    "\n",
    "n = 5\n",
    "options = PipelineOptions(flags=[], type_check_additional='all')\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | f'Count to {n}' >> Count(n)\n",
    "      | 'Print elements' >> beam.Map(print)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from csv file\n",
    "import apache_beam as beam\n",
    "from apache_beam.io.filesystems import FileSystems as beam_fs\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import codecs\n",
    "import csv\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "@beam.ptransform_fn\n",
    "@beam.typehints.with_input_types(beam.pvalue.PBegin)\n",
    "@beam.typehints.with_output_types(Dict[str, str])\n",
    "def ReadCsvFiles(pbegin: beam.pvalue.PBegin, file_patterns: List[str]) -> beam.PCollection[Dict[str, str]]:\n",
    "  def expand_pattern(pattern: str) -> Iterable[str]:\n",
    "    for match_result in beam_fs.match([pattern])[0].metadata_list:\n",
    "      yield match_result.path\n",
    "\n",
    "  def read_csv_lines(file_name: str) -> Iterable[Dict[str, str]]:\n",
    "    with beam_fs.open(file_name) as f:\n",
    "      # Beam reads files as bytes, but csv expects strings,\n",
    "      # so we need to decode the bytes into utf-8 strings.\n",
    "      for row in csv.DictReader(codecs.iterdecode(f, 'utf-8')):\n",
    "        yield dict(row)\n",
    "\n",
    "  return (\n",
    "      pbegin\n",
    "      | 'Create file patterns' >> beam.Create(file_patterns)\n",
    "      | 'Expand file patterns' >> beam.FlatMap(expand_pattern)\n",
    "      | 'Read CSV lines' >> beam.FlatMap(read_csv_lines)\n",
    "  )\n",
    "\n",
    "input_patterns = ['data/*.csv']\n",
    "options = PipelineOptions(flags=[], type_check_additional='all')\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | 'Read CSV files' >> ReadCsvFiles(input_patterns)\n",
    "      | 'Print elements' >> beam.Map(print)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import sqlite3\n",
    "from typing import Iterable, List, Tuple\n",
    "#how to read data from sql lie\n",
    "    #beam.Create will create PCollection with each elements is ('table_name', [column1, column2])\n",
    "    #beam.ParDo() will apply custom tranformation. ParDo will take input with type DoFn\n",
    "class SQLiteSelect(beam.DoFn):\n",
    "\n",
    "    def __init__(self, database_file: str):\n",
    "        self.database_file = database_file\n",
    "        self.connection = None\n",
    "\n",
    "    def setup(self):\n",
    "        self.connection = sqlite3.connect(self.database_file)\n",
    "\n",
    "    def process(self, query: Tuple[str, List[str]]) -> Iterable[Dict[str, str]]:\n",
    "        table, columns = query\n",
    "        cursor = self.connection.cursor()\n",
    "        cursor.execute(f\"SELECT {','.join(columns)} FROM {table}\")\n",
    "        for row in cursor.fetchall():\n",
    "            yield dict(zip(columns, row)) #return a data point as dict('column_name': value)\n",
    "\n",
    "    def teardown(self):\n",
    "        self.connection.close()\n",
    "\n",
    "@beam.ptransform_fn\n",
    "@beam.typehints.with_input_types(beam.pvalue.PBegin)\n",
    "@beam.typehints.with_output_types(Dict[str, str])\n",
    "def SelectFromSQLite(\n",
    "    pbegin: beam.pvalue.PBegin,\n",
    "    database_file: str,\n",
    "    queries: List[Tuple[str, List[str]]],\n",
    ") -> beam.PCollection[Dict[str, str]]:\n",
    "  return (\n",
    "      pbegin\n",
    "      | 'Create None' >> beam.Create(queries)\n",
    "      #for each query fire a query to database with process method\n",
    "      | 'SQLite SELECT' >> beam.ParDo(SQLiteSelect(database_file)) # database_file just for connection with sqlite\n",
    "  )\n",
    "\n",
    "queries = [\n",
    "    # (table_name, [column1, column2, ...])\n",
    "    ('moon_phases', ['phase_emoji', 'peak_datetime', 'phase']),\n",
    "    ('moon_phases', ['phase_emoji', 'phase']),\n",
    "]\n",
    "\n",
    "options = PipelineOptions(flags=[], type_check_additional='all')\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | 'Read from SQLite' >> SelectFromSQLite(database_file, queries)\n",
    "      | 'Print rows' >> beam.Map(print)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Jenny\n",
      "Charles Christy\n",
      "Mike Monica\n"
     ]
    }
   ],
   "source": [
    "#zip to combine each elements of two list\n",
    "a = (\"John\", \"Charles\", \"Mike\")\n",
    "b = (\"Jenny\", \"Christy\", \"Monica\")\n",
    "\n",
    "for x, y in zip(a, b):\n",
    "    print(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a64837e0ff1eebf1c4f61c6be1bef911c548b0d523a16da7fe1c88b4ae3ad6ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
